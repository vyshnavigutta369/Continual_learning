
import matplotlib.pyplot as plt
import numpy as np

# per_class_accuracy= np.load('per_class_accuracy.npy')

per_class_accuracy= [{9: 0.6782, 8: 0.603, 1: 0.9033391915641477, 0: 0.5759717314487632, 7: 0.843585237258348, 3: 0.34581105169340465, 4: 0.5151515151515151, 6: 0.875, 2: 0.5425531914893617, 5: 0.7140350877192982}, {9: 0.8716, 8: 0.8628, 0: 0.920774647887324, 2: 0.9329805996472663, 4: 0.9068541300527241, 7: 0.9804964539007093, 6: 0.9787985865724381, 3: 0.7901234567901234, 1: 0.9875, 5: 0.9664902998236331}, {8: 0.8994, 9: 0.9, 4: 0.9560632688927944, 3: 0.9171075837742504, 1: 0.9911816578483245, 7: 0.9928952042628775, 6: 0.9964664310954063, 5: 0.9823943661971831, 0: 0.9698581560283688, 2: 0.973404255319149}, {8: 0.921, 9: 0.9128, 1: 0.9947460595446584, 4: 0.9767857142857143, 7: 0.9875666074600356, 0: 0.9823943661971831, 2: 0.9804964539007093, 3: 0.9666080843585237, 5: 0.9912126537785588, 6: 0.9946808510638298}, {8: 0.9326, 9: 0.9234, 5: 0.9877622377622378, 0: 0.9929203539823008, 7: 0.991304347826087, 4: 0.9877408056042032, 1: 0.9946902654867257, 6: 0.9910873440285205, 3: 0.9661921708185054, 2: 0.9874326750448833}, {9: 0.9352, 8: 0.9382, 3: 0.9785714285714285, 4: 0.9857397504456328, 7: 0.994661921708185, 6: 0.9892857142857143, 1: 0.9945848375451264, 2: 0.9910873440285205, 0: 0.9858407079646018, 5: 0.9838420107719928}, {8: 0.946, 9: 0.942, 2: 0.9876977152899824, 7: 0.9928825622775801, 0: 0.9892665474060823, 4: 0.9896013864818024, 5: 0.9930191972076788, 3: 0.9802867383512545, 1: 0.9911971830985915, 6: 0.99644128113879}, {8: 0.949, 9: 0.9498, 0: 0.9893238434163701, 3: 0.9857904085257548, 1: 0.998220640569395, 5: 0.9963833634719711, 4: 0.989247311827957, 6: 1.0, 7: 0.998211091234347, 2: 0.9857142857142858}, {8: 0.952, 9: 0.9538, 7: 0.9911971830985915, 5: 0.9911504424778761, 1: 0.9982425307557118, 6: 0.9945945945945946, 0: 0.993006993006993, 3: 0.9875444839857651, 2: 0.9947183098591549, 4: 0.9876977152899824}, {9: 0.957, 8: 0.958, 3: 0.9858407079646018, 4: 0.9929701230228472, 2: 0.9911347517730497, 1: 0.9947368421052631, 7: 0.9982425307557118, 6: 0.9946714031971581, 0: 0.99644128113879, 5: 0.9946996466431095}]
per_class_distribution_shift = [{9: 2.587975390625, 8: 2.405509765625, 1: 3.2247303726384007, 0: 2.4081468346262147, 7: 2.6712311810056018, 3: 2.558689056233289, 4: 2.596228397253788, 6: 2.4523210122551715, 2: 2.286984491010084, 5: 2.1530429773163378}, {9: 2.8044115234375, 8: 2.778683984375, 0: 2.320674842512104, 2: 2.6213533916170637, 4: 2.4976375425637083, 7: 2.9673453256593527, 6: 2.4813370451910335, 3: 2.6267535497271823, 1: 2.9231959751674106, 5: 2.649947985559965}, {8: 3.0156814453125, 9: 2.997103515625, 4: 2.7085454367585675, 3: 3.1135217306685408, 1: 3.0181841707313715, 7: 3.2315071065303065, 6: 2.6284744747957154, 5: 3.0976035964321085, 0: 2.5953074786679964, 2: 3.0178763748060726}, {8: 3.1283123046875, 9: 3.1457220703125, 1: 3.2233574595008756, 4: 3.0162340436662944, 7: 3.254358538937611, 0: 2.875883505377971, 2: 3.2588661139738475, 3: 3.472927636547122, 5: 3.430485569529877, 6: 2.784557802457336}, {8: 3.254812890625, 9: 3.269247265625, 5: 3.498097239674388, 0: 3.0522357231747788, 7: 3.338777598505435, 4: 3.1501779105325087, 1: 3.189310529590708, 6: 2.7979192342775177, 3: 3.69968835145129, 2: 3.566879847747419}, {9: 3.373875, 8: 3.3490265625, 3: 3.8273951939174107, 4: 3.3290330203459226, 7: 3.3634226517320953, 6: 2.988332693917411, 1: 3.3008116574063626, 2: 3.638710824351047, 0: 3.1498414166205753, 5: 3.7040480882517954}, {8: 3.41832265625, 9: 3.3913234375, 2: 3.7974259254173988, 7: 3.4830715410225754, 0: 3.278155659520349, 4: 3.438742705399697, 5: 3.8624410313045376, 3: 4.015068901909722, 1: 3.3638791366362235, 6: 3.0393661553325177}, {8: 3.474483203125, 9: 3.48937265625, 0: 3.3752072154415034, 3: 4.04825788535191, 1: 3.4574869502057384, 5: 3.8329579248135173, 4: 3.476686757952509, 6: 3.1176825027059283, 7: 3.495902892302102, 2: 3.96871337890625}, {8: 3.54153046875, 9: 3.57847109375, 7: 3.523990684831646, 5: 3.9841520326327435, 1: 3.603737883073374, 6: 3.1541035420185812, 0: 3.4684183614237325, 3: 4.134338161699288, 2: 4.123989481321523, 4: 3.675922842981107}, {9: 3.585567578125, 8: 3.577193359375, 3: 4.277425850387168, 4: 3.6628284957161688, 2: 3.984868475731383, 1: 3.743751284950658, 7: 3.6878681417508785, 6: 3.2794163434585926, 0: 3.5789968687444396, 5: 4.0211250655642665}]

# class_mapping= {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5:}
class_mapping= {0: 0, 1: 1, 2: 4, 3: 5, 4: 6, 5: 7, 6: 8, 7: 9, 8: 2, 9: 3}
names_to_labels = {0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}

per_class_accuracy_new = {}


for epochs_dict in per_class_distribution_shift:
    for label in epochs_dict:
        if label not in per_class_accuracy_new.keys():
            per_class_accuracy_new[label] = []
        per_class_accuracy_new[label].append(epochs_dict[label])

for k, v in per_class_accuracy_new.items():
    plt.plot(range(1, len(v) + 1), v, '.-', label=names_to_labels[class_mapping[k]])
    # NOTE: changed `range(1, 4)` to mach actual values count

x = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44]
xi = list(range(len(x)))
plt.legend()  # To draw legend
plt.xlabel('epochs')
plt.xticks(xi, x)
plt.ylabel('distribution shift between task one and task two model')
# plt.ylabel('accuracy') 
# plt.savefig('per_class_accuracyf.png')
plt.savefig('per_class_shift.png')

